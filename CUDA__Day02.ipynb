{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxgSpUkrKlFIRol6at4Af7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjivch/100-days-of-gpu/blob/main/CUDA__Day02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cikt-Cg4FEtf",
        "outputId": "5dd49fd7-b111-4e01-9864-affa921b209a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtYTeKY1FIjW",
        "outputId": "6b1a126b-1260-4b6c-b1f6-e630c8de801d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpys6_d6k4\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "__global__ void matAdd(const float* A, const float* B, float* C, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if ((i >= N) && (j >= N)) { // guard block\n",
        "        return ;\n",
        "    }\n",
        "\n",
        "    C[i*N+j] = A[i*N+j] + B[i*N+j];\n",
        "\n",
        "    }\n",
        "\n",
        "int main() {\n",
        "    const int N = 5;\n",
        "    float *A, *B, *C;\n",
        "\n",
        "    // initialize the input matrices\n",
        "    A = (float *)malloc( N*N* sizeof(float));\n",
        "    B = (float *)malloc(N*N* sizeof(float));\n",
        "    C = (float *)malloc(N*N * sizeof(float));\n",
        "\n",
        "    // Hardcode values for A, B and C\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        for (int j = 0; j < N; j++)\n",
        "        {\n",
        "            A[i * N + j] = 10.0f;\n",
        "            B[i * N + j] = 20.0f;\n",
        "            C[i * N + j] = 0.0f;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    float *d_a, *d_b,*d_c;\n",
        "\n",
        "    // Allocate memory on host\n",
        "    cudaMalloc((void **)&d_a, N*N*sizeof(float));\n",
        "    cudaMalloc((void **)&d_b, N*N*sizeof(float));\n",
        "    cudaMalloc((void **)&d_c, N*N*sizeof(float));\n",
        "\n",
        "    // Transfer to device\n",
        "    cudaMemcpy(d_a, A, N*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, B, N*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    dim3 dimBlock(32, 16);\n",
        "    dim3 dimGrid(ceil(N / 32.0f), ceil(N/ 16.0f));\n",
        "    matAdd<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Synchronize threads on device\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Transfer back to host\n",
        "    cudaMemcpy(C, d_c, N*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Check outputs\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "\n",
        "            printf(\"%.4f \",C[i * N + j]);\n",
        "            printf(\"%.4f \", A[i * N + j]);\n",
        "            printf(\"%.4f \", B[i * N + j]);\n",
        "\n",
        "        }\n",
        "            printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "\n",
        "    // Free resources\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXt4Qia7FMxZ",
        "outputId": "f755ac0b-4dcb-46fc-d7e3-ddc6927fa120"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 \n",
            "30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 \n",
            "30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 \n",
            "30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 \n",
            "30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 30.0000 10.0000 20.0000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEIkeaZlJTtW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}